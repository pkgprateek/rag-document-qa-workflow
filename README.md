# RAG Document Question Answer System

> Production-ready RAG-powered document Q&A with automated CI/CD deployment

[![Deploy to HF](https://github.com/pkgprateek/ai-rag-document/actions/workflows/deploy-to-hf.yml/badge.svg)](https://github.com/pkgprateek/ai-rag-document/actions/workflows/deploy-to-hf.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Gradio](https://img.shields.io/badge/Gradio-5.49.1-orange)](https://gradio.app/)

---

## Live Demo

**Try it now**: [RAG Document QA on Hugging Face Spaces](https://huggingface.co/spaces/pkgprateek/ai-rag-document)

Upload documents (PDF, DOCX, TXT) and ask questions - get citation-backed answers powered by RAG.

---

## Key Features

- **Multi-Format Support**: Handles PDF, DOCX, and TXT documents with intelligent parsing
- **Citation-Backed Answers**: Every response includes source references from your documents
- **Persistent Vector Store**: ChromaDB ensures data survives application restarts
- **Rate Limiting**: Built-in API abuse prevention (10 queries/hour)
- **Automated CI/CD**: GitHub Actions deploys to Hugging Face Spaces on every commit
- **Auto-Cleanup**: User documents deleted after 7 days (samples persist)
- **Docker Ready**: Fast, reproducible deployments with UV package manager

---

## Architecture

### System Components

**Document Processing Pipeline**:
- Multi-format ingestion â†’ Text extraction â†’ Intelligent chunking (1000 chars, 200 overlap) â†’ Metadata preservation

**Retrieval System**:
- BAAI/bge-small-en-v1.5 embeddings (384-dim) â†’ ChromaDB vector store â†’ Top-4 semantic search with cosine similarity

**Generation**:
- Google Gemma 3-4B-IT via OpenRouter â†’ Temperature 0.1 for factual responses â†’ Context-grounded output (no hallucinations)

---

## Quick Start

### Prerequisites
- Python 3.10+
- OpenRouter API key ([Get free tier](https://openrouter.ai/keys))

### Installation (Docker - Recommended)

```bash
# Clone repository
git clone https://github.com/pkgprateek/rag-document-qa-workflow.git
cd rag-document-qa-workflow

# Set environment variables
cp .env.example .env
# Edit .env and add: OPENROUTER_API_KEY=your_key_here

# Run with Docker
docker compose up
```

Application starts at `http://localhost:7860`

### Installation (Local with UV)

```bash
# Install UV (10x faster than pip)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add: OPENROUTER_API_KEY=your_key_here

# Run application
python app/main.py
```

---

## Project Structure

```
rag-document-qa-workflow/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-to-hf.yml      # CI/CD pipeline
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                   # Gradio UI and entry point
â”‚   â”œâ”€â”€ rag_pipeline.py           # RAG chain implementation
â”‚   â””â”€â”€ document_processor.py     # Document parsing & chunking
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/               # Vector database (gitignored)
â”‚   â”œâ”€â”€ samples/                 # Pre-loaded demo documents
â”‚   â””â”€â”€ rate_limit.json          # Rate limiting state
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_rag_pipeline.py
â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â””â”€â”€ experiments.py
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ docker-compose.yml           # Local development setup
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ CLAUDE.md                   # Enterprise polish checklist
â””â”€â”€ README.md                   # This file (dev-focused)
```

**Note**: The README on HuggingFace Spaces is user-focused. This README is for developers.

---

## ðŸš€ Deployment

### Automated Deployment (CI/CD)

Every push to `main` automatically deploys to Hugging Face Spaces via GitHub Actions.

**Setup GitHub Secret**:
1. Get HF token: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) (Write access)
2. Add to GitHub: `Settings â†’ Secrets â†’ Actions â†’ New repository secret`
3. Name: `HF_TOKEN`, Value: your token
4. Push to main - deployment happens automatically

**Deployment Flow**:
```
Local Changes â†’ git push â†’ GitHub â†’ Actions Workflow â†’ Hugging Face Spaces â†’ Live
```

### Manual Deployment

```bash
# If needed, you can manually push to HF
git push hfspace main
```

---

## ðŸ’» Development

### Running Tests

```bash
pytest tests/
```

### Environment Variables

Required in `.env`:
```bash
OPENROUTER_API_KEY=your_key_here  # Get from https://openrouter.ai/keys
```

### Rate Limiting

- **Default**: 10 queries per hour
- **State**: Tracked in `data/rate_limit.json`
- **Customization**: Modify `MAX_REQUESTS` in `app/rag_pipeline.py`

### Auto-Cleanup

User-uploaded documents are automatically deleted after 7 days:
- Implemented in `app/rag_pipeline.py` with timestamp tracking
- Sample documents in `data/samples/` are never deleted
- Manual cleanup: Call `RAGPipeline.cleanup_old_documents()`

---

## Docker & UV

### Why Docker?
- **Reproducible**: Same environment everywhere (dev, staging, prod)
- **Fast**: Build caching speeds up iterations
- **Isolated**: No dependency conflicts

### Why UV?
- **10x faster** than pip for dependency resolution
- **Deterministic**: Lock files ensure consistency
- **Rust-powered**: Modern, reliable tooling

### Docker Build

```bash
docker build -t rag-document-qa .
docker run -p 7860:7860 --env-file .env rag-document-qa
```

---

## Future Enhancements

- [ ] Multi-document cross-referencing
- [ ] Conversation history for context-aware follow-ups
- [ ] Hybrid search (semantic + keyword BM25)
- [ ] Advanced chunking strategies (semantic boundaries)
- [ ] Multimodal support (images, tables)
- [ ] User authentication & document management
- [ ] Automated testing in CI pipeline

---

## Performance Metrics

- **Embedding Speed**: ~500ms for 1000-char chunk
- **Retrieval Latency**: <100ms for top-4 results
- **Generation Time**: 2-5s (depends on OpenRouter load)
- **Storage**: ~10MB per 100-page document

---

## License

This project is available under the MIT License - see LICENSE file for details.

---

## Contact

**Prateek Kumar Goel**

- GitHub: [@pkgprateek](https://github.com/pkgprateek)
- Hugging Face: [@pkgprateek](https://huggingface.co/pkgprateek)
- Live Demo: [RAG Document QA](https://huggingface.co/spaces/pkgprateek/ai-rag-document)

---

## Acknowledgments

Built with modern MLOps best practices:
- Automated CI/CD deployment
- Infrastructure as Code (GitHub Actions + Docker)
- Encrypted secrets management
- Version-controlled deployment workflows

**For Recruiters**: This project demonstrates production-grade software engineering practices including automated deployment pipelines, containerization, proper error handling, clean architecture, and professional documentation standards used at FAANG companies.
