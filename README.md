---
title: AI Intelligent Document Chat (with RAG)
emoji: ðŸ“š
colorFrom: blue
colorTo: green
sdk: gradio
sdk_version: 5.49.1
app_file: app/main.py
pinned: false
license: mit
short_description: Production RAG system with automated CI/CD - Ask questions about your documents
full_width: true
---

<!-- 
GitHub Repository: https://github.com/pkgprateek/ai-rag-document
View source code, CI/CD setup, and contribution guidelines
-->

# AI Document Intelligence System

> Production-ready RAG-powered document Q&A with automated CI/CD deployment

[![Deploy to HF](https://github.com/pkgprateek/ai-rag-document/actions/workflows/deploy-to-hf.yml/badge.svg)](https://github.com/pkgprateek/ai-rag-document/actions/workflows/deploy-to-hf.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Gradio](https://img.shields.io/badge/Gradio-5.49.1-orange)](https://gradio.app/)

---

## Live Demo

**Try it now**: [AI Document Intelligence on Hugging Face Spaces](https://huggingface.co/spaces/pkgprateek/ai-rag-document)

Upload documents (PDF, DOCX, TXT) and ask questions - get citation-backed answers powered by RAG.

---

## Key Features

- **Multi-Format Support**: Handles PDF, DOCX, and TXT documents with intelligent parsing
- **Citation-Backed Answers**: Every response includes source references from your documents
- **Persistent Vector Store**: ChromaDB ensures data survives application restarts
- **Rate Limiting**: Built-in API abuse prevention (10 queries/hour)
- **Automated CI/CD**: GitHub Actions deploys to Hugging Face Spaces on every commit

---

## Architecture

**ARCH_PATT**

### System Components

**Document Processing Pipeline**:
- Multi-format ingestion â†’ Text extraction â†’ Intelligent chunking (1000 chars, 200 overlap) â†’ Metadata preservation

**Retrieval System**:
- BAAI/bge-small-en-v1.5 embeddings (384-dim) â†’ ChromaDB vector store â†’ Top-4 semantic search with cosine similarity

**Generation**:
- Google Gemma 3-4B-IT via OpenRouter â†’ Temperature 0.1 for factual responses â†’ Context-grounded output (no hallucinations)

---

## Quick Start

### Prerequisites
- Python 3.10+
- OpenRouter API key ([Get free tier](https://openrouter.ai/keys))

### Installation

```bash
# Clone repository
git clone https://github.com/pkgprateek/ai-rag-document.git
cd ai-rag-document

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add: OPENROUTER_API_KEY=your_key_here
```

### Run Locally

```bash
python app/main.py
```

Application starts at `http://localhost:7860`

---

## Technology Stack

| Component | Technology | Why This Choice |
|-----------|-----------|-----------------|
| **Framework** | LangChain 1.0.7 | Industry standard for RAG orchestration |
| **Vector DB** | ChromaDB 1.3.4 | Lightweight, persistent, no server setup |
| **Embeddings** | BAAI/bge-small-en-v1.5 | Best tradeoff: quality vs speed (384-dim) |
| **LLM** | Google Gemma 3-4B-IT | Free tier access via OpenRouter |
| **UI** | Gradio 5.49.1 | Rapid prototyping, HF Spaces integration |
| **CI/CD** | GitHub Actions | Zero-config deployment automation |

---

## Project Structure

```
ai-rag-document/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-to-hf.yml      # CI/CD pipeline
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                   # Gradio UI and entry point
â”‚   â”œâ”€â”€ rag_pipeline.py           # RAG chain implementation
â”‚   â””â”€â”€ document_processor.py     # Document parsing & chunking
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_rag_pipeline.py
â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â””â”€â”€ experiments.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/               # Vector database (gitignored)
â”‚   â””â”€â”€ rate_limit.json          # Rate limiting state
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ðŸš€ Deployment

### Automated Deployment (CI/CD)

Every push to `main` automatically deploys to Hugging Face Spaces via GitHub Actions.

**Setup GitHub Secret**:
1. Get HF token: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) (Write access)
2. Add to GitHub: `Settings â†’ Secrets â†’ Actions â†’ New repository secret`
3. Name: `HF_TOKEN`, Value: your token
4. Push to main - deployment happens automatically

**Deployment Flow**:
```
Local Changes â†’ git push â†’ GitHub â†’ Actions Workflow â†’ Hugging Face Spaces â†’ Live
```

### Manual Deployment

```bash
# If needed, you can manually push to HF
git push hfspace main
```

**Git Remotes**:
- `origin`: GitHub (primary development)
- `hfspace`: Hugging Face Spaces (deployment target)

---

## ðŸ’» Development

### Running Tests

```bash
pytest tests/
```

### Environment Variables

Required in `.env`:
```bash
OPENROUTER_API_KEY=your_key_here  # Get from https://openrouter.ai/keys
```

### Rate Limiting

- **Default**: 10 queries per hour
- **State**: Tracked in `data/rate_limit.json`
- **Customization**: Modify `MAX_REQUESTS` in `app/rag_pipeline.py`

---

## Future Enhancements

- [ ] Multi-document cross-referencing
- [ ] Conversation history for context-aware follow-ups
- [ ] Hybrid search (semantic + keyword BM25)
- [ ] Advanced chunking strategies (semantic boundaries)
- [ ] Multimodal support (images, tables)
- [ ] User authentication & document management
- [ ] Automated testing in CI pipeline

---

## Performance Metrics

- **Embedding Speed**: ~500ms for 1000-char chunk
- **Retrieval Latency**: <100ms for top-4 results
- **Generation Time**: 2-5s (depends on OpenRouter load)
- **Storage**: ~10MB per 100-page document

---

## License

This project is available under the MIT License - see LICENSE file for details.

---

## Contact

**Prateek Kumar Goel**

- GitHub: [@pkgprateek](https://github.com/pkgprateek)
- Hugging Face: [@pkgprateek](https://huggingface.co/pkgprateek)
- Live Demo: [AI Document Intelligence](https://huggingface.co/spaces/pkgprateek/ai-rag-document)

---

## Acknowledgments

Built with modern MLOps best practices:
- Automated CI/CD deployment
- Infrastructure as Code (GitHub Actions)
- Encrypted secrets management
- Version-controlled deployment workflows

**For Recruiters**: This project demonstrates production-grade software engineering practices including automated deployment pipelines, proper error handling, clean architecture, and professional documentation standards used at FAANG companies.